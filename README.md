# Racism Exposure Estimator

Using **machine learning**, we've developed a predictive model that estimates an individual's likelihood of facing discrimination.  
The goal is **not** to promote division, but to **raise awareness** and provoke thoughtful discussion about unconscious bias and systemic inequities.

---

## ðŸ“Š About the Project

This project explores how societal perceptionsâ€”based on physical appearance, nationality, and other external attributesâ€”might influence discriminatory experiences. 

The model was trained on a dataset built with **genuine research and careful consideration**. It **does not include any fabricated or biased data points**.  
We emphasize: the model reflects observable **trends**, not **moral truths**, and **must not** be used to label individuals or make decisions about real people.

---

## Disclaimer

> **This is a delicate topic.**  
> We urge all users to approach this tool with **empathy**, **humility**, and **understanding**.  
> Our goal is to **educate**, **inform**, and promote thoughtful reflectionâ€”not to stereotype or judge.

---

## Key Features Used in Prediction

- **Skin tone**, **nationality**, and **accent** were found to be the **strongest influencing factors**.
- Additional features include:
  - **BMI**
  - **Hair texture**
  - **Fashion style**
  - **Gender presentation**
  - **Religious symbols**
- These variables were chosen based on insights from **sociological studies** on bias and perception.

---

## Ethical Considerations

- No **personal** or **sensitive** real-user data was used.
- The model runs in a **simulated environment** purely for **educational** and **awareness-raising** purposes.
- Predictions are not definitive, and should not be interpreted as facts.

---

## Try It Yourself

A Streamlit web app allows users to experiment with input features and view how the model responds.  
You can access the deployed app and explore how various combinations affect the predicted exposure score.

---

## Connect with the Developer

[GitHub](https://github.com/Arhamhir) | [LinkedIn](https://www.linkedin.com/in/arham-tahir-95626a28a/)

---

> If you have feedback, concerns, or want to collaborate on improving fairness in AI, feel free to reach out.

